# -*- coding: utf-8 -*-
"""logistic_regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PGKeWCrZpmMCjAmXuiqTsP3A1Fi7jsl7
"""

## Logistic Regression For Binary Image Classification
# Updated 3/5/2024
# Created 3/2/2024 - Joseph Huang and Nikhita Anantha Madhaven
'''
This logistic regression algorithm is designed to determine if an inputted image
is an image of a resistor or not. If probabilty of resistor is greater than
0.5 it is classfied as a resistor, otherwise it is something else.
'''

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/MyDrive/VIP-SD(Spring2024)/

import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

## Resize RGB image to 100Ã—250
'''
All images are passed through this function to ensure consistancy in
image size. The aspect ratio is appropriate for the shape of resistors
'''
def resize_image(imageFile):
  img = plt.imread(imageFile)
  img_nparray = np.array(img)

  resized_img = np.zeros((100, 250, 3))
  for i in range(100):
    for j in range(250):
      new_i = int((i * img_nparray.shape[0] / 100))
      new_j = int((j * img_nparray.shape[1] / 250))
      resized_img[i,j] = img_nparray[new_i, new_j]
  return resized_img

# Flatten image
'''
Images are flattened into a 1D array, esentially creating a feature
vector where each pixel is a "feature"
'''
def extract_features(image_path):
  with open(image_path, 'rb') as filename:
    resized_img = resize_image(filename)
    flattened_image = resized_img.flatten()
  return flattened_image

# Make list of feature vectors
'''
Each element in the list is the feature vector for an
image in the folder
'''
def create_feature_list(folder):
  images = os.listdir(folder)
  features_list = []
  for name in images:
    image_path = os.path.join(folder, name)
    curr_feature = extract_features(image_path)
    features_list.append(curr_feature)
  features_list_nparray = np.array(features_list)
  return features_list_nparray

# Load the resistor images (104 total images)
resistor_folder = "resistor_train_images"
resistor_features = create_feature_list(resistor_folder)
resistor_labels = np.ones((resistor_features.shape[0], 1))

#Load the random images (100 total images)
non_resistor_folder = "random_train_images"
non_resistor_features = create_feature_list(non_resistor_folder)
non_resistor_labels = np.zeros((non_resistor_features.shape[0], 1))

# Vertically stack features and labels
x = np.vstack((resistor_features, non_resistor_features))
y = np.vstack((resistor_labels, non_resistor_labels))

# Add intercept term to x (this is necessary to account for bias or offset)
intercept = np.ones((x.shape[0], 1))
x = np.hstack((intercept, x))

# Split the data into training and testing sets
'''
This code sets a random seed for replication purposes and splits the data into
train and test data. The last 20 images are test data, everything else is
training data
'''
np.random.seed(18)
indices = np.random.permutation(x.shape[0])
X_train, X_test = x[indices[:-20]], x[indices[-20:]]
y_train, y_test = y[indices[:-20]], y[indices[-20:]]

# Sigmoid function
def sigmoid(z):
    return (1 / (1 + np.exp(-z)))

# Cost function
def cost_function(X, y, theta):
    m = len(y)
    h = sigmoid(np.dot(X, theta))
    cost = (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))
    return cost

# Gradient descent
def gradient_descent(X, y, theta, alpha, num_iterations):
    m = len(y)
    costs = []
    for _ in range(num_iterations):
        h = sigmoid(np.dot(X, theta))
        gradient = np.dot(X.T, (h - y)) / m
        theta -= alpha * gradient
        cost = cost_function(X, y, theta)
        costs.append(cost)
    return theta, costs

# Initialize theta
theta = np.zeros((X_train.shape[1], 1))

alpha = 0.01
num_iterations = 1000

# Train the model
theta, costs = gradient_descent(X_train, y_train, theta, alpha, num_iterations)

predictions = np.round(sigmoid(np.dot(X_test, theta)))
accuracy = np.mean(predictions == y_test)
print("Accuracy:", accuracy)

test_image_path = "IMG_3915.jpg"

features = extract_features(test_image_path)
test_features = np.hstack(([1], features))

probability = sigmoid(np.dot(test_features, theta))
predicted_label = "resistor" if probability >= 0.5 else "not resistor"

print("Predicted label:", predicted_label)